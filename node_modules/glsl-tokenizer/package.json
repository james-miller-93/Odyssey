{
  "_args": [
    [
      {
        "raw": "glsl-tokenizer@^2.0.2",
        "scope": null,
        "escapedName": "glsl-tokenizer",
        "name": "glsl-tokenizer",
        "rawSpec": "^2.0.2",
        "spec": ">=2.0.2 <3.0.0",
        "type": "range"
      },
      "/Users/Roula/Odyssey/node_modules/glsl-shader-name"
    ]
  ],
  "_from": "glsl-tokenizer@>=2.0.2 <3.0.0",
  "_id": "glsl-tokenizer@2.1.2",
  "_inCache": true,
  "_location": "/glsl-tokenizer",
  "_nodeVersion": "6.2.0",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/glsl-tokenizer-2.1.2.tgz_1464276268897_0.221282874699682"
  },
  "_npmUser": {
    "name": "mattdesl",
    "email": "dave.des@gmail.com"
  },
  "_npmVersion": "3.8.9",
  "_phantomChildren": {
    "core-util-is": "1.0.2",
    "inherits": "2.0.3",
    "isarray": "0.0.1",
    "string_decoder": "0.10.31",
    "xtend": "4.0.1"
  },
  "_requested": {
    "raw": "glsl-tokenizer@^2.0.2",
    "scope": null,
    "escapedName": "glsl-tokenizer",
    "name": "glsl-tokenizer",
    "rawSpec": "^2.0.2",
    "spec": ">=2.0.2 <3.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/glsl-shader-name"
  ],
  "_resolved": "https://registry.npmjs.org/glsl-tokenizer/-/glsl-tokenizer-2.1.2.tgz",
  "_shasum": "720307522e03c57af35c00551950c4a70ef2dfb9",
  "_shrinkwrap": null,
  "_spec": "glsl-tokenizer@^2.0.2",
  "_where": "/Users/Roula/Odyssey/node_modules/glsl-shader-name",
  "author": {
    "name": "Chris Dickinson",
    "email": "chris@neversaw.us"
  },
  "authors": [
    "Hugh Kennedy <hughskennedy@gmail.com> (http://hughsk.io/)",
    "Mikola Lysenko <mikolalysenko@gmail.com> (http://0fps.net)",
    "Chris Dickinson <chris@neversaw.us> (http://neversaw.us)"
  ],
  "bugs": {
    "url": "https://github.com/gl-modules/glsl-tokenizer/issues"
  },
  "dependencies": {
    "through2": "^0.6.3"
  },
  "description": "r/w stream of glsl tokens",
  "devDependencies": {
    "tap-spec": "^1.0.1",
    "tape": "^3.0.2"
  },
  "directories": {
    "test": "test"
  },
  "dist": {
    "shasum": "720307522e03c57af35c00551950c4a70ef2dfb9",
    "tarball": "https://registry.npmjs.org/glsl-tokenizer/-/glsl-tokenizer-2.1.2.tgz"
  },
  "gitHead": "e7520f8741259051a74840e32f34d8b97877d519",
  "homepage": "https://github.com/gl-modules/glsl-tokenizer#readme",
  "keywords": [
    "glsl",
    "tokenizer",
    "stream"
  ],
  "license": "MIT",
  "main": "string.js",
  "maintainers": [
    {
      "name": "chrisdickinson",
      "email": "chris@neversaw.us"
    },
    {
      "name": "gre",
      "email": "renaudeau.gaetan@gmail.com"
    },
    {
      "name": "hughsk",
      "email": "hughskennedy@gmail.com"
    },
    {
      "name": "mattdesl",
      "email": "dave.des@gmail.com"
    },
    {
      "name": "mikkoh",
      "email": "me@mikkoh.com"
    },
    {
      "name": "mikolalysenko",
      "email": "mikolalysenko@gmail.com"
    },
    {
      "name": "rezaali",
      "email": "syed.reza.ali@gmail.com"
    },
    {
      "name": "substack",
      "email": "substack@gmail.com"
    },
    {
      "name": "tatumcreative",
      "email": "tatum.creative@gmail.com"
    },
    {
      "name": "thibauts",
      "email": "thibaut.seguy@gmail.com"
    },
    {
      "name": "wwwtyro",
      "email": "wwwtyro@gmail.com"
    },
    {
      "name": "yoshuawuyts",
      "email": "i@yoshuawuyts.com"
    }
  ],
  "name": "glsl-tokenizer",
  "optionalDependencies": {},
  "readme": "# glsl-tokenizer\n\nMaps GLSL string data into GLSL tokens, either synchronously or using a\nstreaming API.\n\n``` javascript\nvar tokenString = require('glsl-tokenizer/string')\nvar tokenStream = require('glsl-tokenizer/stream')\nvar fs = require('fs')\n\n// Synchronously:\nvar tokens = tokenString(fs.readFileSync('some.glsl'))\n\n// Streaming API:\nfs.createReadStream('some.glsl')\n  .pipe(tokenStream())\n  .on('data', function(token) {\n    console.log(token.data, token.position, token.type)\n  })\n```\n\n# API\n\n## tokens = require('glsl-tokenizer/string')(src, [opt])\n\nReturns an array of `tokens` given the GLSL source string `src`\n\nYou can specify `opt.version` string to use different keywords/builtins, such as `'300 es'` for WebGL2. Otherwise, will assume GLSL 100 (WebGL1).\n\n```js\nvar tokens = tokenizer(src, {\n  version: '300 es'\n})\n```\n\n## stream = require('glsl-tokenizer/stream')([opt])\n\nEmits 'data' events whenever a token is parsed with a token object as output.\n\nAs above, you can specify `opt.version`.\n\n# Tokens\n\n```javascript\n{ 'type': TOKEN_TYPE\n, 'data': \"string of constituent data\"\n, 'position': integer position within the GLSL source\n, 'line': line number within the GLSL source\n, 'column': column number within the GLSL source }\n```\n\nThe available token types are:\n\n* `block-comment`: `/* ... */`\n* `line-comment`: `// ... \\n`\n* `preprocessor`: `# ... \\n`\n* `operator`: Any operator. If it looks like punctuation, it's an operator.\n* `float`: Optionally suffixed with `f`\n* `ident`: User defined identifier.\n* `builtin`: Builtin function.\n* `eof`: Emitted on `end`; data will === `'(eof)'`.\n* `integer`\n* `whitespace`\n* `keyword`\n\n# License\n\nMIT, see [LICENSE.md](LICENSE.md) for further information.\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git://github.com/gl-modules/glsl-tokenizer.git"
  },
  "scripts": {
    "test": "node test/index.js | tap-spec"
  },
  "version": "2.1.2"
}
